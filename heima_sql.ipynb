{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8b2be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3595c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "        appName(\"test\").\\\n",
    "        master('local[*]').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124425b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"./people.txt\").map(lambda x: x.split(\", \")).\\\n",
    "        map(lambda x: (x[0], int(x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a49e9b",
   "metadata": {},
   "source": [
    "# 自动判别字段类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a188bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=['name', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd183ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9b61fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 16|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9ced57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createTempView('people')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10c5da45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "| Justin| 16|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM people WHERE age < 30').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b6c26",
   "metadata": {},
   "source": [
    "# 使用StructType构建DataFrame表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c24235d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb1c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"name\", StringType(), True).\\\n",
    "            add(\"age\", IntegerType(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9fa5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d979874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 16|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc373a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ad0db9",
   "metadata": {},
   "source": [
    "# 使用RDD的toDF方法转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29b18b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF(schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c58c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|Michael| 29|\n",
      "|   Andy| 30|\n",
      "| Justin| 16|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d6354",
   "metadata": {},
   "source": [
    "# 源数据来自于Pandas的DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c40d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a2299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = pd.DataFrame({\n",
    "    \"id\": [1, 2, 3],\n",
    "    \"name\": ['Jack', 'Justin', 'Ala'],\n",
    "    \"age\": [11, 13 ,14]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7003b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df_pd, schema=['id', 'name', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25bcea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| id|  name|age|\n",
      "+---+------+---+\n",
      "|  1|  Jack| 11|\n",
      "|  2|Justin| 13|\n",
      "|  3|   Ala| 14|\n",
      "+---+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036f68f",
   "metadata": {},
   "source": [
    "# 统一API从文件读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b19d2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"value\", StringType(), True) # text文件\n",
    "df = spark.read.format(\"text\").schema(schema=schema).load(\"./people.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a05853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      value|\n",
      "+-----------+\n",
      "|Michael, 29|\n",
      "|   Andy, 30|\n",
      "| Justin, 16|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79edcf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  14|   Mike|\n",
      "|  18|   Mike|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"json\").load(\"./people.json\")  # json文件\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cd974c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType().add(\"name\", StringType(), True).\\\n",
    "            add(\"age\", IntegerType(), False).add(\"job\", StringType(), False)\n",
    "df = spark.read.format(\"csv\").option(\"sep\", \";\").\\\n",
    "    option(\"header\", True).option(\"encoding\", \"utf-8\").\\\n",
    "    schema(schema).load(\"./people.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8383695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+\n",
      "| name|age|      job|\n",
      "+-----+---+---------+\n",
      "|Jorge| 30|Developer|\n",
      "|  Bob| 32|  Manager|\n",
      "|Alice|  9|Developer|\n",
      "+-----+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b39dc75",
   "metadata": {},
   "source": [
    "# DataFrame编程：DSL和SQL风格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e80fab29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+\n",
      "| name|age|      job|\n",
      "+-----+---+---------+\n",
      "|Jorge| 30|Developer|\n",
      "|  Bob| 32|  Manager|\n",
      "|Alice|  9|Developer|\n",
      "+-----+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f5f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Jorge| 30|\n",
      "|  Bob| 32|\n",
      "|Alice|  9|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([\"name\", \"age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90267d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+\n",
      "| name|age|      job|\n",
      "+-----+---+---------+\n",
      "|Jorge| 30|Developer|\n",
      "|Alice|  9|Developer|\n",
      "+-----+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age < 31\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9891b05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---------+\n",
      "| name|age|      job|\n",
      "+-----+---+---------+\n",
      "|Jorge| 30|Developer|\n",
      "|Alice|  9|Developer|\n",
      "+-----+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df['age'] < 31).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e50accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| name|count|\n",
      "+-----+-----+\n",
      "|  Bob|    1|\n",
      "|Jorge|    1|\n",
      "|Alice|    1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df['name']).count().show() # groupBy的返回值是GroupData类型\n",
    "# GroupData类型：有分组关系的数据结构\n",
    "# 接上聚合函数API：sum, avg, count, min, max\n",
    "# 通过聚合函数后返回的是DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f17228",
   "metadata": {},
   "source": [
    "# word count demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65947b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c86e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('./words.txt').flatMap(lambda x: x.split(\" \")).map(lambda x: [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "737f993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.toDF([\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d67ccae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createTempView(\"words\") # SQL风格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "123ccfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  word|cnt|\n",
      "+------+---+\n",
      "| hello|  3|\n",
      "| flink|  1|\n",
      "| spark|  1|\n",
      "|hadoop|  1|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT word, COUNT(*) AS cnt FROM words GROUP BY word ORDER BY cnt DESC\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "183919c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSL风格\n",
    "df = spark.read.format(\"text\").load(\"./words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa4a8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# withColumn方法\n",
    "df2 = df.withColumn(\"value\", F.explode(F.split(df['value'], \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb9df52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "| hello|    3|\n",
      "| flink|    1|\n",
      "| spark|    1|\n",
      "|hadoop|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(\"value\").count().withColumnRenamed(\"value\", \"word\").\\\n",
    "    orderBy(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0d1fe",
   "metadata": {},
   "source": [
    "# 电影评分案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5d31316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=StructType().add(\"user_id\", IntegerType(), False).add(\"movie_id\", IntegerType(), False).\\\n",
    "    add(\"rank\", IntegerType(), False).add(\"ts\", StringType(), False)\n",
    "df = spark.read.format(\"csv\").schema(schema=schema).option(\"header\", False).\\\n",
    "    option(\"encoding\", \"utf-8\").option(\"sep\", \"\\t\").load(\"./u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "760c234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|user_id|avg_rank|\n",
      "+-------+--------+\n",
      "|    849|    4.87|\n",
      "|    688|    4.83|\n",
      "|    507|    4.72|\n",
      "|    628|     4.7|\n",
      "|    928|    4.69|\n",
      "+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO:用户的平均分\n",
    "df.groupBy(\"user_id\").avg(\"rank\").withColumnRenamed(\"avg(rank)\", \"avg_rank\").\\\n",
    "        withColumn(\"avg_rank\", F.round(\"avg_rank\", 2)).orderBy(\"avg_rank\",ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "043e9080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|movie_id|avg_rank|\n",
      "+--------+--------+\n",
      "|    1122|     5.0|\n",
      "|    1500|     5.0|\n",
      "|    1201|     5.0|\n",
      "|    1653|     5.0|\n",
      "+--------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO:电影的平均分查询,采用SQL风格 --> SQL一步到位，需要很熟悉\n",
    "df.createOrReplaceTempView(\"movie\")\n",
    "spark.sql(\"SELECT movie_id, ROUND(AVG(rank), 2) AS avg_rank FROM movie GROUP BY movie_id ORDER BY avg_rank DESC\").show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8db9f242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55375"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:查询大于电影平均分的数量\n",
    "df.where(df['rank'] > df.select(F.avg(df['rank'])).first()['avg(rank)']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "319d40c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO：查询大于3分电影中，打分次数最多的用户，此人打分的平均分\n",
    "df.where(df[\"rank\"]>3).groupBy(\"user_id\").count().orderBy(\"count\", ascending=False).first()['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5d2e35b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|round(avg(rank), 2)|\n",
      "+-------------------+\n",
      "|               3.86|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算这个人的打分平均分\n",
    "df.filter(df['user_id']==450).select(F.round(F.avg(\"rank\"), 2)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef6ba4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+\n",
      "|user_id|avg_rank|min_rank|max_rank|\n",
      "+-------+--------+--------+--------+\n",
      "|    148|     4.0|       1|       5|\n",
      "|    463|    2.86|       1|       5|\n",
      "|    471|    3.39|       1|       5|\n",
      "|    496|    3.03|       1|       5|\n",
      "+-------+--------+--------+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO:查询每个用户的平均打分，最低打分，最高打分\n",
    "df.groupBy(\"user_id\").\\\n",
    "    agg(\n",
    "        F.round(F.avg(\"rank\"), 2).alias(\"avg_rank\"),\n",
    "        F.min(\"rank\").alias(\"min_rank\"),\n",
    "        F.max(\"rank\").alias(\"max_rank\")\n",
    "    ).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93850691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+--------+\n",
      "|movie_id|cnt|avg_rank|\n",
      "+--------+---+--------+\n",
      "|     408|112|    4.49|\n",
      "|     169|118|    4.47|\n",
      "|     318|298|    4.47|\n",
      "|     483|243|    4.46|\n",
      "|      64|283|    4.45|\n",
      "+--------+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO:查询评分超过100次的电影的平均分\n",
    "df.groupBy(\"movie_id\").\\\n",
    "    agg(\n",
    "        F.count(\"movie_id\").alias(\"cnt\"),\n",
    "        F.round(F.avg(\"rank\"), 2).alias(\"avg_rank\")\n",
    "    ).where(\"cnt > 100\").orderBy(\"avg_rank\", ascending=False).\\\n",
    "    show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed072476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1、agg函数：它是GroupData对象的API，作用是可以在里面写多个聚合；\n",
    "2、alias：它是Column对象的API可以对一个列进行改名；\n",
    "3、withColumnRenamed：它是DataFrame的API，可以对DF中的列进行改名；与alias不同\n",
    "4、orderBy：DataFrame的API，对DF进行排序；\n",
    "5、first：DataFrame的API，取出第一行，返回Row对象；\n",
    "# Row对象可通过row['列名']来取出当前行中，某一列的具体数值；\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291f2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一API数据写出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd95330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869beef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d6439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
